{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c7a1c5-f393-43b2-83ae-1cb6f938b91d",
   "metadata": {},
   "source": [
    "# Root Mean Square Normalization ( RMSNorm ) Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523176b1-32fd-4c98-8753-fc743c08e43f",
   "metadata": {},
   "source": [
    "## CL Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f51cac-d360-4fb7-a254-91a78c9ea028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\bin\\Hostx86\\x86\\cl.exe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] += r';C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX86\\x86'\n",
    "\n",
    "!where cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bd98e-c34b-404c-a2ee-e5bb17d9a7fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746fcd89-4987-466c-9eee-cd69add1b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: numpy in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\ovuru\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\rope_cuda-0.0.0-py3.12-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e3735-dcad-4c01-8518-4681a558ebc2",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4b2ac4-1fd2-4899-9eac-75d14b4d16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as N\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Any, Type, Tuple\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5a77f-d4a4-401c-a452-9f4a3e16dc9a",
   "metadata": {},
   "source": [
    "## Define Utility Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af561496-f4ff-41be-8f66-afcc94672fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkCase(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a test case for benchmarking neural network layers.\n",
    "\n",
    "    Attributes:\n",
    "        test_name (str): Name of the test case.\n",
    "        original_layer (Type[N.Module]): The original layer class to be tested.\n",
    "        new_layer (Type[N.Module]): The new layer class to be compared against the original.\n",
    "        layer_args (Dict[str, Any]): Positional arguments for layer initialization.\n",
    "        layer_kwargs (Dict[str, Any]): Keyword arguments for layer initialization.\n",
    "        forward_args (Dict[str, Any]): Positional arguments for the forward pass.\n",
    "        forward_kwargs (Dict[str, Any]): Keyword arguments for the forward pass.\n",
    "        num_iterations (int): Number of iterations for each test run.\n",
    "        num_runs (int): Number of test runs to perform.\n",
    "\n",
    "    Example:\n",
    "        TestCase(\n",
    "            test_name=\"RoPE Test\",\n",
    "            original_layer=RoPEOriginal,\n",
    "            new_layer=Rope,\n",
    "            layer_args={},\n",
    "            layer_kwargs={\"dim\": 1000, \"end\": 1000},\n",
    "            forward_args={},\n",
    "            forward_kwargs={\"dim\": 1000, \"end\": 1000},\n",
    "            num_iterations=1000,\n",
    "            num_runs=100\n",
    "        )\n",
    "    \"\"\"\n",
    "    test_name: str\n",
    "    original_layer: Type[N.Module]\n",
    "    new_layer: Type[N.Module]\n",
    "    layer_args: Dict[str, Any] = Field(default_factory=dict)\n",
    "    layer_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "    forward_args: Dict[str, Any] = Field(default_factory=dict)\n",
    "    forward_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "    num_iterations: int = 1000\n",
    "    num_runs: int = 100\n",
    "\n",
    "class LayerTestResult(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the result of a single layer test run.\n",
    "\n",
    "    Attributes:\n",
    "        execution_time (float): The execution time of the layer.\n",
    "        output: The output of the layer's forward pass.\n",
    "    \"\"\"\n",
    "    execution_time: float\n",
    "    output: Any\n",
    "\n",
    "class TestRunResult(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the result of a single test run comparing two layers.\n",
    "\n",
    "    Attributes:\n",
    "        speedup (float): The speedup factor of the new layer compared to the original.\n",
    "        max_diff (float): The maximum absolute difference between the outputs.\n",
    "        mean_diff (float): The mean absolute difference between the outputs.\n",
    "        new_layer_result (LayerTestResult): The test result for the new layer.\n",
    "        original_layer_result (LayerTestResult): The test result for the original layer.\n",
    "    \"\"\"\n",
    "    speedup: float\n",
    "    max_diff: float\n",
    "    mean_diff: float\n",
    "    new_layer_result: LayerTestResult\n",
    "    original_layer_result: LayerTestResult\n",
    "\n",
    "class BlackBoxTestResult(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the overall result of black box testing for a test case.\n",
    "\n",
    "    Attributes:\n",
    "        test_case (BenchmarkCase): The test case that was run.\n",
    "        results (List[TestRunResult]): The results of all test runs.\n",
    "    \"\"\"\n",
    "    test_case: BenchmarkCase\n",
    "    results: List[TestRunResult]\n",
    "\n",
    "class BenchmarkAnalysis(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the analysis of benchmark results.\n",
    "\n",
    "    Attributes:\n",
    "        avg_speedup (float): The average speedup across all runs.\n",
    "        std_speedup (float): The standard deviation of speedup.\n",
    "        min_speedup (float): The minimum speedup observed.\n",
    "        max_speedup (float): The maximum speedup observed.\n",
    "        avg_max_diff (float): The average of maximum differences.\n",
    "        avg_mean_diff (float): The average of mean differences.\n",
    "        new_layer_stats (Dict[str, float]): Statistics for the new layer's performance.\n",
    "        original_layer_stats (Dict[str, float]): Statistics for the original layer's performance.\n",
    "    \"\"\"\n",
    "    avg_speedup: float\n",
    "    std_speedup: float\n",
    "    min_speedup: float\n",
    "    max_speedup: float\n",
    "    avg_max_diff: float\n",
    "    avg_mean_diff: float\n",
    "    new_layer_stats: Dict[str, float]\n",
    "    original_layer_stats: Dict[str, float]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeae4eb-8c56-43a0-8f20-0487a93662b2",
   "metadata": {},
   "source": [
    "# Base RMS Norm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555def0d-0ac1-408f-94c2-35eb5bbb9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Black Forest Labs\n",
    "# Reference: https://github.com/black-forest-labs/flux/blob/478338d52759f92af9eeb92cc9eaa49582b20c78/src/flux/modules/layers.py#L63\n",
    "class BaseRMSNorm(N.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.scale = torch.nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_dtype = x.dtype\n",
    "        x = x.float()\n",
    "        rrms = torch.rsqrt(torch.mean(x * x, dim=-1, keepdim=True) + 1e-6)\n",
    "        return (x * rrms).to(dtype=x_dtype) * self.scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1345d4-9f20-4080-a762-76cddd27ea71",
   "metadata": {},
   "source": [
    "# Our Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1efbdc4-ec5e-4246-a614-1235ad19eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\ovuru\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py312_cu124 as PyTorch extensions root...\n",
      "The input conditions for extension module our_extension have changed. Bumping to version 3 and re-building as our_extension_v3...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\ovuru\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py312_cu124\\our_extension\\build.ninja...\n",
      "Building extension module our_extension_v3...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module our_extension_v3...\n"
     ]
    }
   ],
   "source": [
    "cuda_source =\"\"\"\n",
    "#include <torch/extension.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cuda_fp16.h>\n",
    "#include <cooperative_groups.h>\n",
    "#include <algorithm>\n",
    "\n",
    "\n",
    "template <typename scalar_t>\n",
    "__global__ void rmsnorm_cuda_forward_kernel(\n",
    "    const scalar_t* __restrict__ input,\n",
    "    const scalar_t* __restrict__ scale,\n",
    "    scalar_t* __restrict__ output,\n",
    "    uint64_t dim\n",
    "    ) {\n",
    "    __shared__ float shared_sum;\n",
    "\n",
    "    const float float_dim = static_cast<float>(dim);\n",
    "\n",
    "    const uint64_t input_idx = threadIdx.x + blockIdx.z * blockDim.x + blockIdx.y * blockDim.x * gridDim.z + blockIdx.x * blockDim.x * gridDim.y * gridDim.z;\n",
    "\n",
    "    if (threadIdx.x == 0){\n",
    "        shared_sum = 0;\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    float item_mean = static_cast<float>(input[input_idx] * input[input_idx]);\n",
    "    atomicAdd(&shared_sum, item_mean);\n",
    "    __syncthreads();\n",
    "\n",
    "    if (threadIdx.x == 0){\n",
    "        shared_sum = rsqrt(shared_sum / float_dim + 1e-6);\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    output[input_idx] = static_cast<scalar_t>(input[input_idx] * shared_sum * scale[input_idx % dim]);\n",
    "}\n",
    "\n",
    "torch::Tensor rmsnorm_forward(\n",
    "    torch::Tensor input,\n",
    "    torch::Tensor scale) {\n",
    "    auto output = torch::empty_like(input);\n",
    "    // Check if 3-d or 4-d, it cannot be 2-d or 5-d>\n",
    "    const int input_dims = input.dim();\n",
    "\n",
    "    if (input_dims < 3 || input_dims > 4) {\n",
    "        throw std::invalid_argument(\"Input must be 3-d or 4-d tensor\");\n",
    "    }\n",
    "    if (input_dims == 3) {\n",
    "        input = input.unsqueeze(0);\n",
    "    }\n",
    "\n",
    "    uint64_t x = input.size(0);\n",
    "    uint64_t y = input.size(1);\n",
    "    uint64_t z = input.size(2);\n",
    "    uint64_t threads_per_block = input.size(3);\n",
    "\n",
    "    dim3 blocks_per_grid(x, y, z);\n",
    "\n",
    "    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"rmsnorm_forward_cuda\", ([&] {\n",
    "        rmsnorm_cuda_forward_kernel<scalar_t><<<blocks_per_grid, threads_per_block>>>(\n",
    "            input.data_ptr<scalar_t>(),\n",
    "            scale.data_ptr<scalar_t>(),\n",
    "            output.data_ptr<scalar_t>(),\n",
    "            threads_per_block\n",
    "        );\n",
    "    }));\n",
    "\n",
    "    return output;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cpp_source = \"\"\"\n",
    "torch::Tensor rmsnorm_forward(\n",
    "    torch::Tensor input,\n",
    "    torch::Tensor scale);\n",
    "\"\"\"\n",
    "\n",
    "our_extension = load_inline(\n",
    "    name='our_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['rmsnorm_forward'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O3\",],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "class OurRMSNorm(BaseRMSNorm):\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return our_extension.rmsnorm_forward(x, self.scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b9b708-8194-491b-b35a-2e8a3484bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rmsnorm_forward(norm_class, shape, dtype, device, input_tensor):\n",
    "    dim = shape[-1]\n",
    "    input_tensor = input_tensor.to(device, dtype)\n",
    "    norm = norm_class(dim).to(device, dtype)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    output = norm(input_tensor)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    return end_time - start_time, output\n",
    "\n",
    "\n",
    "def run_tests(\n",
    "    shape: Tuple[int, ...],\n",
    "    dtype: torch.dtype,\n",
    "    device: str,\n",
    "    test_name: str,\n",
    "    num_runs: int = 100,\n",
    ") -> List[Tuple[float, float, float, float, float]]:\n",
    "    results = []\n",
    "    for _ in range(num_runs):\n",
    "        input_tensor = torch.randn(*shape, dtype=dtype, device=device)\n",
    "        cuda_time, cuda_output = test_rmsnorm_forward(OurRMSNorm, shape, dtype, device, input_tensor)\n",
    "        original_time, original_output = test_rmsnorm_forward(\n",
    "            BaseRMSNorm, shape, dtype, device, input_tensor\n",
    "        )\n",
    "\n",
    "        speedup = original_time / cuda_time if cuda_time > 0 else float(\"inf\")\n",
    "        max_diff = torch.max(torch.abs(cuda_output - original_output)).item()\n",
    "        mean_diff = torch.mean(torch.abs(cuda_output - original_output)).item()\n",
    "\n",
    "        results.append((speedup, max_diff, mean_diff, cuda_time, original_time))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_results(\n",
    "    results: List[Tuple[float, float, float, float, float]]\n",
    ") -> Tuple[float, float, float, float, float, float, List[float], List[float]]:\n",
    "    speedups, max_diffs, mean_diffs, cuda_times, original_times = zip(*results)\n",
    "\n",
    "    avg_speedup = np.mean(speedups)\n",
    "    std_speedup = np.std(speedups)\n",
    "    avg_max_diff = np.mean(max_diffs)\n",
    "    avg_mean_diff = np.mean(mean_diffs)\n",
    "\n",
    "    cuda_stats = [\n",
    "        np.mean(cuda_times),\n",
    "        np.min(cuda_times),\n",
    "        np.max(cuda_times),\n",
    "        np.std(cuda_times),\n",
    "    ]\n",
    "    original_stats = [\n",
    "        np.mean(original_times),\n",
    "        np.min(original_times),\n",
    "        np.max(original_times),\n",
    "        np.std(original_times),\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        avg_speedup,\n",
    "        std_speedup,\n",
    "        np.min(speedups),\n",
    "        np.max(speedups),\n",
    "        avg_max_diff,\n",
    "        avg_mean_diff,\n",
    "        cuda_stats,\n",
    "        original_stats,\n",
    "    )\n",
    "\n",
    "\n",
    "def print_analysis(\n",
    "    test_name: str,\n",
    "    input_shape: Tuple[int, ...],\n",
    "    dtype: torch.dtype,\n",
    "    device: str,\n",
    "    analysis: Tuple[float, float, float, float, float, float, List[float], List[float]],\n",
    "):\n",
    "    (\n",
    "        avg_speedup,\n",
    "        std_speedup,\n",
    "        min_speedup,\n",
    "        max_speedup,\n",
    "        avg_max_diff,\n",
    "        avg_mean_diff,\n",
    "        cuda_stats,\n",
    "        original_stats,\n",
    "    ) = analysis\n",
    "\n",
    "    print(f\"\\n{test_name} Test\")\n",
    "    print(f\"Input shape: {input_shape}\")\n",
    "    print(f\"Data type: {dtype}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Average Speedup: {avg_speedup:.2f}x (±{std_speedup:.2f})\")\n",
    "    print(f\"Speedup Range: {min_speedup:.2f}x - {max_speedup:.2f}x\")\n",
    "    print(f\"Average Max Diff: {avg_max_diff:.6f}\")\n",
    "    print(f\"Average Mean Diff: {avg_mean_diff:.6f}\")\n",
    "\n",
    "    print(\"\\nCUDA Implementation:\")\n",
    "    print(f\"  Average Time: {cuda_stats[0]:.6f} seconds\")\n",
    "    print(f\"  Min Time: {cuda_stats[1]:.6f} seconds\")\n",
    "    print(f\"  Max Time: {cuda_stats[2]:.6f} seconds\")\n",
    "    print(f\"  Std Dev Time: {cuda_stats[3]:.6f} seconds\")\n",
    "\n",
    "    print(\"\\nOriginal Implementation:\")\n",
    "    print(f\"  Average Time: {original_stats[0]:.6f} seconds\")\n",
    "    print(f\"  Min Time: {original_stats[1]:.6f} seconds\")\n",
    "    print(f\"  Max Time: {original_stats[2]:.6f} seconds\")\n",
    "    print(f\"  Std Dev Time: {original_stats[3]:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d05df773-f1fb-43ce-8fb8-045562429cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Small 3D Test\n",
      "Input shape: (1, 1, 32)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 3.12x (±0.77)\n",
      "Speedup Range: 1.08x - 3.87x\n",
      "Average Max Diff: 0.000000\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000192 seconds\n",
      "  Min Time: 0.000055 seconds\n",
      "  Max Time: 0.001182 seconds\n",
      "  Std Dev Time: 0.000332 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000369 seconds\n",
      "  Min Time: 0.000185 seconds\n",
      "  Max Time: 0.001276 seconds\n",
      "  Std Dev Time: 0.000317 seconds\n",
      "\n",
      "Medium 3D Test\n",
      "Input shape: (32, 128, 512)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 4.22x (±1.70)\n",
      "Speedup Range: 2.43x - 8.16x\n",
      "Average Max Diff: 0.000002\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000093 seconds\n",
      "  Min Time: 0.000052 seconds\n",
      "  Max Time: 0.000155 seconds\n",
      "  Std Dev Time: 0.000035 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000357 seconds\n",
      "  Min Time: 0.000204 seconds\n",
      "  Max Time: 0.000521 seconds\n",
      "  Std Dev Time: 0.000106 seconds\n",
      "\n",
      "Large 3D Test\n",
      "Input shape: (128, 256, 512)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 3.56x (±1.33)\n",
      "Speedup Range: 1.17x - 6.72x\n",
      "Average Max Diff: 0.000003\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000080 seconds\n",
      "  Min Time: 0.000050 seconds\n",
      "  Max Time: 0.000215 seconds\n",
      "  Std Dev Time: 0.000046 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000249 seconds\n",
      "  Min Time: 0.000189 seconds\n",
      "  Max Time: 0.000463 seconds\n",
      "  Std Dev Time: 0.000078 seconds\n",
      "\n",
      "Small 4D Test\n",
      "Input shape: (1, 1, 1, 32)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 4.51x (±0.70)\n",
      "Speedup Range: 3.41x - 5.68x\n",
      "Average Max Diff: 0.000000\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000042 seconds\n",
      "  Min Time: 0.000036 seconds\n",
      "  Max Time: 0.000058 seconds\n",
      "  Std Dev Time: 0.000006 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000186 seconds\n",
      "  Min Time: 0.000159 seconds\n",
      "  Max Time: 0.000224 seconds\n",
      "  Std Dev Time: 0.000017 seconds\n",
      "\n",
      "Medium 4D Test\n",
      "Input shape: (2, 16, 32, 1024)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 4.94x (±2.23)\n",
      "Speedup Range: 3.04x - 11.31x\n",
      "Average Max Diff: 0.000003\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000049 seconds\n",
      "  Min Time: 0.000036 seconds\n",
      "  Max Time: 0.000101 seconds\n",
      "  Std Dev Time: 0.000018 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000225 seconds\n",
      "  Min Time: 0.000159 seconds\n",
      "  Max Time: 0.000442 seconds\n",
      "  Std Dev Time: 0.000083 seconds\n",
      "\n",
      "Large 4D Test\n",
      "Input shape: (8, 16, 32, 1024)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 6.33x (±4.28)\n",
      "Speedup Range: 2.23x - 14.90x\n",
      "Average Max Diff: 0.000003\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000091 seconds\n",
      "  Min Time: 0.000047 seconds\n",
      "  Max Time: 0.000156 seconds\n",
      "  Std Dev Time: 0.000032 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000493 seconds\n",
      "  Min Time: 0.000211 seconds\n",
      "  Max Time: 0.001021 seconds\n",
      "  Std Dev Time: 0.000220 seconds\n",
      "\n",
      "Data type: torch.float32 Test\n",
      "Input shape: (32, 128, 512)\n",
      "Data type: torch.float32\n",
      "Device: cuda\n",
      "Average Speedup: 4.20x (±1.43)\n",
      "Speedup Range: 2.98x - 8.33x\n",
      "Average Max Diff: 0.000002\n",
      "Average Mean Diff: 0.000000\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000074 seconds\n",
      "  Min Time: 0.000048 seconds\n",
      "  Max Time: 0.000114 seconds\n",
      "  Std Dev Time: 0.000021 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000302 seconds\n",
      "  Min Time: 0.000183 seconds\n",
      "  Max Time: 0.000441 seconds\n",
      "  Std Dev Time: 0.000097 seconds\n",
      "\n",
      "Data type: torch.float16 Test\n",
      "Input shape: (32, 128, 512)\n",
      "Data type: torch.float16\n",
      "Device: cuda\n",
      "Average Speedup: 6.40x (±3.46)\n",
      "Speedup Range: 2.80x - 14.14x\n",
      "Average Max Diff: 0.003125\n",
      "Average Mean Diff: 0.000006\n",
      "\n",
      "CUDA Implementation:\n",
      "  Average Time: 0.000086 seconds\n",
      "  Min Time: 0.000048 seconds\n",
      "  Max Time: 0.000123 seconds\n",
      "  Std Dev Time: 0.000022 seconds\n",
      "\n",
      "Original Implementation:\n",
      "  Average Time: 0.000495 seconds\n",
      "  Min Time: 0.000234 seconds\n",
      "  Max Time: 0.000800 seconds\n",
      "  Std Dev Time: 0.000174 seconds\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_cases = [\n",
    "    (\"Small 3D\", (1, 1, 32)),\n",
    "    (\"Medium 3D\", (32, 128, 512)),\n",
    "    (\"Large 3D\", (128, 256, 512)),\n",
    "    (\"Small 4D\", (1, 1, 1, 32)),\n",
    "    (\"Medium 4D\", (2, 16, 32, 1024)),\n",
    "    (\"Large 4D\", (8, 16, 32, 1024)),\n",
    "]\n",
    "\n",
    "for name, shape in test_cases:\n",
    "    results = run_tests(shape, torch.float32, device, name, num_runs)\n",
    "    analysis = analyze_results(results)\n",
    "    print_analysis(name, shape, torch.float32, device, analysis)\n",
    "\n",
    "# Additional tests for different data types\n",
    "data_types = [torch.float32, torch.float16]\n",
    "for dtype in data_types:\n",
    "    shape = (32, 128, 512)\n",
    "    results = run_tests(shape, dtype, device, f\"Data type: {dtype}\", num_runs)\n",
    "    analysis = analyze_results(results)\n",
    "    print_analysis(f\"Data type: {dtype}\", shape, dtype, device, analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272af72-2282-4640-91e7-b2d6d211c390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbdfd64-5fb5-4257-9f60-4376b2c7a287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cef3b0-3c09-440d-bf84-81c8aae6e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
